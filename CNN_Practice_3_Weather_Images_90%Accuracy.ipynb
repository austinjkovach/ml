{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "data_dir = 'datasets/weather_images/'\n",
    "image_paths = glob.glob(data_dir + '*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['cloudy', 'rain', 'shine', 'sunrise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image_paths = [glob.glob(data_dir + 'train/' + l + '/*.jpg') for l in labels]\n",
    "test_image_paths = [glob.glob(data_dir + 'test/' + l + '/*.jpg') for l in labels]\n",
    "validation_image_paths = [glob.glob(data_dir + 'validation/' + l + '/*.jpg') for l in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/952914/how-to-make-a-flat-list-out-of-list-of-lists\n",
    "def flatten(list):\n",
    "    return [item for sublist in list for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image_paths_flat = flatten(training_image_paths)\n",
    "test_image_paths_flat = flatten(test_image_paths)\n",
    "validation_image_paths_flat = flatten(validation_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(labels, dataset_paths):\n",
    "    output_labels = []\n",
    "    for x in range(len(labels)):\n",
    "        for y in dataset_paths[x]:\n",
    "            output_labels.append(x)\n",
    "    return output_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels = create_labels(labels, training_image_paths)\n",
    "test_labels = create_labels(labels, test_image_paths)\n",
    "validation_labels = create_labels(labels, validation_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "####################STOP######################\n",
    "##############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "####################GO########################\n",
    "##############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That's the Magic \n",
    "# Cast data\n",
    "training_imgs = np.array([np.array(tf.keras.preprocessing.image.load_img(x, color_mode='rgb',\n",
    "    target_size=(64, 64)), np.float32) for x in training_image_paths_flat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "training_img_labels = np.array(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot(targets, num_classes):\n",
    "    res = np.eye(num_classes)[np.array(targets).reshape(-1)]\n",
    "    return res.reshape(list(targets.shape)+[num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = training_imgs, training_img_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = get_one_hot(y_train, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped_training = list(zip(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(zipped_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = list(zip(*zipped_training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(868, 64, 64, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(868, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs = np.array([np.array(tf.keras.preprocessing.image.load_img(x, color_mode='rgb',\n",
    "    target_size=(64, 64)), np.float32) for x in test_image_paths_flat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = test_imgs, test_img_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = get_one_hot(y_test, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAvgPool2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='Adam',\n",
    "    metrics=['accuravacy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 868 samples, validate on 153 samples\n",
      "Epoch 1/50\n",
      "868/868 [==============================] - 12s 14ms/sample - loss: 261.6363 - accuracy: 0.3525 - val_loss: 31.6422 - val_accuracy: 0.4837\n",
      "Epoch 2/50\n",
      "868/868 [==============================] - 10s 11ms/sample - loss: 12.1929 - accuracy: 0.6613 - val_loss: 1.6783 - val_accuracy: 0.7451\n",
      "Epoch 3/50\n",
      "868/868 [==============================] - 9s 11ms/sample - loss: 1.9703 - accuracy: 0.6924 - val_loss: 0.9314 - val_accuracy: 0.6405\n",
      "Epoch 4/50\n",
      "868/868 [==============================] - 9s 11ms/sample - loss: 0.9493 - accuracy: 0.7154 - val_loss: 0.8413 - val_accuracy: 0.7320\n",
      "Epoch 5/50\n",
      "868/868 [==============================] - 10s 11ms/sample - loss: 0.7451 - accuracy: 0.7120 - val_loss: 0.7659 - val_accuracy: 0.7255\n",
      "Epoch 6/50\n",
      "868/868 [==============================] - 9s 11ms/sample - loss: 0.6599 - accuracy: 0.7408 - val_loss: 0.8673 - val_accuracy: 0.6209\n",
      "Epoch 7/50\n",
      "868/868 [==============================] - 10s 11ms/sample - loss: 0.5717 - accuracy: 0.7558 - val_loss: 0.7365 - val_accuracy: 0.7320\n",
      "Epoch 8/50\n",
      "868/868 [==============================] - 9s 11ms/sample - loss: 0.5196 - accuracy: 0.7823 - val_loss: 0.6880 - val_accuracy: 0.7451\n",
      "Epoch 9/50\n",
      "868/868 [==============================] - 10s 11ms/sample - loss: 0.5084 - accuracy: 0.7776 - val_loss: 0.7127 - val_accuracy: 0.7516\n",
      "Epoch 10/50\n",
      "868/868 [==============================] - 9s 11ms/sample - loss: 0.4539 - accuracy: 0.8134 - val_loss: 0.6383 - val_accuracy: 0.8039\n",
      "Epoch 11/50\n",
      "868/868 [==============================] - 9s 11ms/sample - loss: 0.4074 - accuracy: 0.8260 - val_loss: 0.6355 - val_accuracy: 0.8170\n",
      "Epoch 12/50\n",
      "868/868 [==============================] - 10s 11ms/sample - loss: 0.3280 - accuracy: 0.8525 - val_loss: 0.6361 - val_accuracy: 0.8039\n",
      "Epoch 13/50\n",
      "868/868 [==============================] - 10s 11ms/sample - loss: 0.3366 - accuracy: 0.8641 - val_loss: 0.5614 - val_accuracy: 0.8170\n",
      "Epoch 14/50\n",
      "868/868 [==============================] - 9s 11ms/sample - loss: 0.3220 - accuracy: 0.8548 - val_loss: 0.7409 - val_accuracy: 0.8039\n",
      "Epoch 15/50\n",
      "868/868 [==============================] - 10s 11ms/sample - loss: 0.2452 - accuracy: 0.8940 - val_loss: 0.5388 - val_accuracy: 0.8497\n",
      "Epoch 16/50\n",
      "868/868 [==============================] - 9s 11ms/sample - loss: 0.2434 - accuracy: 0.9021 - val_loss: 0.5603 - val_accuracy: 0.8366\n",
      "Epoch 17/50\n",
      "868/868 [==============================] - 9s 11ms/sample - loss: 0.2488 - accuracy: 0.8882 - val_loss: 0.6213 - val_accuracy: 0.8431\n",
      "Epoch 18/50\n",
      "868/868 [==============================] - 9s 11ms/sample - loss: 0.2156 - accuracy: 0.9009 - val_loss: 0.5332 - val_accuracy: 0.8301\n",
      "Epoch 19/50\n",
      "868/868 [==============================] - 9s 11ms/sample - loss: 0.2131 - accuracy: 0.9159 - val_loss: 0.5340 - val_accuracy: 0.8366\n",
      "Epoch 20/50\n",
      "868/868 [==============================] - 9s 11ms/sample - loss: 0.2273 - accuracy: 0.8952 - val_loss: 0.4459 - val_accuracy: 0.8627\n",
      "Epoch 21/50\n",
      "868/868 [==============================] - 10s 11ms/sample - loss: 0.2178 - accuracy: 0.9159 - val_loss: 0.5091 - val_accuracy: 0.8497\n",
      "Epoch 22/50\n",
      "868/868 [==============================] - 10s 11ms/sample - loss: 0.2245 - accuracy: 0.9182 - val_loss: 0.5374 - val_accuracy: 0.8301\n",
      "Epoch 23/50\n",
      "868/868 [==============================] - 9s 11ms/sample - loss: 0.1905 - accuracy: 0.9171 - val_loss: 0.8067 - val_accuracy: 0.8301\n",
      "Epoch 24/50\n",
      "868/868 [==============================] - 10s 11ms/sample - loss: 0.1796 - accuracy: 0.9228 - val_loss: 0.5933 - val_accuracy: 0.8627\n",
      "Epoch 25/50\n",
      "868/868 [==============================] - 10s 11ms/sample - loss: 0.1507 - accuracy: 0.9447 - val_loss: 0.5701 - val_accuracy: 0.9150\n",
      "Epoch 26/50\n",
      "868/868 [==============================] - 10s 11ms/sample - loss: 0.1773 - accuracy: 0.9366 - val_loss: 0.6165 - val_accuracy: 0.8562\n",
      "Epoch 27/50\n",
      "868/868 [==============================] - 9s 11ms/sample - loss: 0.1554 - accuracy: 0.9355 - val_loss: 0.7357 - val_accuracy: 0.8954\n",
      "Epoch 28/50\n",
      "868/868 [==============================] - 9s 11ms/sample - loss: 0.2230 - accuracy: 0.9240 - val_loss: 0.5160 - val_accuracy: 0.8366\n",
      "Epoch 29/50\n",
      "868/868 [==============================] - 10s 11ms/sample - loss: 0.2164 - accuracy: 0.9090 - val_loss: 0.5262 - val_accuracy: 0.8431\n",
      "Epoch 30/50\n",
      "868/868 [==============================] - 9s 11ms/sample - loss: 0.2058 - accuracy: 0.9147 - val_loss: 0.5868 - val_accuracy: 0.8693\n",
      "Epoch 31/50\n",
      "868/868 [==============================] - 9s 11ms/sample - loss: 0.2016 - accuracy: 0.9228 - val_loss: 0.4498 - val_accuracy: 0.8627\n",
      "Epoch 32/50\n",
      "868/868 [==============================] - 10s 11ms/sample - loss: 0.1969 - accuracy: 0.9309 - val_loss: 0.6992 - val_accuracy: 0.8431\n",
      "Epoch 33/50\n",
      "868/868 [==============================] - 9s 11ms/sample - loss: 0.1900 - accuracy: 0.9401 - val_loss: 0.7914 - val_accuracy: 0.8497\n",
      "Epoch 34/50\n",
      "868/868 [==============================] - 9s 11ms/sample - loss: 0.1651 - accuracy: 0.9343 - val_loss: 0.6952 - val_accuracy: 0.9085\n",
      "Epoch 35/50\n",
      "868/868 [==============================] - 9s 11ms/sample - loss: 0.1185 - accuracy: 0.9493 - val_loss: 0.4870 - val_accuracy: 0.8758\n",
      "Epoch 36/50\n",
      "868/868 [==============================] - 9s 11ms/sample - loss: 0.1291 - accuracy: 0.9539 - val_loss: 0.7065 - val_accuracy: 0.8889\n",
      "Epoch 37/50\n",
      "868/868 [==============================] - 9s 11ms/sample - loss: 0.1208 - accuracy: 0.9562 - val_loss: 0.6390 - val_accuracy: 0.8758\n",
      "Epoch 38/50\n",
      "868/868 [==============================] - 10s 11ms/sample - loss: 0.1310 - accuracy: 0.9505 - val_loss: 0.6204 - val_accuracy: 0.8562\n",
      "Epoch 39/50\n",
      "868/868 [==============================] - 9s 11ms/sample - loss: 0.2013 - accuracy: 0.9159 - val_loss: 0.4995 - val_accuracy: 0.8497\n",
      "Epoch 40/50\n",
      "868/868 [==============================] - 9s 11ms/sample - loss: 0.1369 - accuracy: 0.9401 - val_loss: 1.1077 - val_accuracy: 0.8693\n",
      "Epoch 41/50\n",
      "868/868 [==============================] - 10s 11ms/sample - loss: 0.1738 - accuracy: 0.9539 - val_loss: 0.5580 - val_accuracy: 0.8627\n",
      "Epoch 42/50\n",
      "868/868 [==============================] - 9s 11ms/sample - loss: 0.1208 - accuracy: 0.9631 - val_loss: 0.5932 - val_accuracy: 0.8889\n",
      "Epoch 43/50\n",
      "868/868 [==============================] - 9s 11ms/sample - loss: 0.1164 - accuracy: 0.9539 - val_loss: 0.5076 - val_accuracy: 0.8627\n",
      "Epoch 44/50\n",
      "868/868 [==============================] - 9s 11ms/sample - loss: 0.1066 - accuracy: 0.9562 - val_loss: 0.8161 - val_accuracy: 0.8627\n",
      "Epoch 45/50\n",
      "868/868 [==============================] - 10s 11ms/sample - loss: 0.1076 - accuracy: 0.9608 - val_loss: 0.7512 - val_accuracy: 0.8562\n",
      "Epoch 46/50\n",
      "868/868 [==============================] - 9s 11ms/sample - loss: 0.1207 - accuracy: 0.9585 - val_loss: 0.8728 - val_accuracy: 0.8693\n",
      "Epoch 47/50\n",
      "868/868 [==============================] - 9s 11ms/sample - loss: 0.1253 - accuracy: 0.9562 - val_loss: 0.6842 - val_accuracy: 0.8693\n",
      "Epoch 48/50\n",
      "868/868 [==============================] - 9s 11ms/sample - loss: 0.0880 - accuracy: 0.9643 - val_loss: 0.7880 - val_accuracy: 0.8889\n",
      "Epoch 49/50\n",
      "868/868 [==============================] - 9s 11ms/sample - loss: 0.1102 - accuracy: 0.9758 - val_loss: 0.8603 - val_accuracy: 0.8889\n",
      "Epoch 50/50\n",
      "868/868 [==============================] - 9s 11ms/sample - loss: 0.0885 - accuracy: 0.9758 - val_loss: 0.7442 - val_accuracy: 0.9085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x126f067d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 50\n",
    "batch_size = 128\n",
    "\n",
    "# Fit the model weights.\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1, validation_data=(x_test, y_test)\n",
    ")\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              multiple                  896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            multiple                  18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  7372928   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  516       \n",
      "=================================================================\n",
      "Total params: 7,392,836\n",
      "Trainable params: 7,392,836\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153/1 - 0s - loss: 0.5250 - accuracy: 0.9085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7441960617997287, 0.90849674]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model2.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model2.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Dropout(0.25))\n",
    "model2.add(Flatten())\n",
    "\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='Adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 868 samples, validate on 153 samples\n",
      "Epoch 1/50\n",
      "868/868 [==============================] - 15s 18ms/sample - loss: 17.8986 - accuracy: 0.3848 - val_loss: 1.3465 - val_accuracy: 0.6078\n",
      "Epoch 2/50\n",
      "868/868 [==============================] - 13s 15ms/sample - loss: 2.1675 - accuracy: 0.6221 - val_loss: 1.0325 - val_accuracy: 0.6340\n",
      "Epoch 3/50\n",
      "868/868 [==============================] - 12s 14ms/sample - loss: 1.1572 - accuracy: 0.6555 - val_loss: 0.7108 - val_accuracy: 0.7516\n",
      "Epoch 4/50\n",
      "868/868 [==============================] - 12s 14ms/sample - loss: 0.7398 - accuracy: 0.7465 - val_loss: 0.5855 - val_accuracy: 0.8170\n",
      "Epoch 5/50\n",
      "868/868 [==============================] - 12s 14ms/sample - loss: 0.5293 - accuracy: 0.7995 - val_loss: 0.5597 - val_accuracy: 0.8431\n",
      "Epoch 6/50\n",
      "868/868 [==============================] - 12s 14ms/sample - loss: 0.5702 - accuracy: 0.8076 - val_loss: 0.6081 - val_accuracy: 0.7778\n",
      "Epoch 7/50\n",
      "868/868 [==============================] - 12s 13ms/sample - loss: 0.5338 - accuracy: 0.7880 - val_loss: 0.5140 - val_accuracy: 0.8366\n",
      "Epoch 8/50\n",
      "868/868 [==============================] - 12s 14ms/sample - loss: 0.4057 - accuracy: 0.8479 - val_loss: 0.5081 - val_accuracy: 0.8301\n",
      "Epoch 9/50\n",
      "868/868 [==============================] - 12s 13ms/sample - loss: 0.3726 - accuracy: 0.8790 - val_loss: 0.4863 - val_accuracy: 0.8627\n",
      "Epoch 10/50\n",
      "868/868 [==============================] - 12s 14ms/sample - loss: 0.3109 - accuracy: 0.8836 - val_loss: 0.4167 - val_accuracy: 0.8693\n",
      "Epoch 11/50\n",
      "868/868 [==============================] - 12s 14ms/sample - loss: 0.2982 - accuracy: 0.8998 - val_loss: 0.4294 - val_accuracy: 0.8758\n",
      "Epoch 12/50\n",
      "868/868 [==============================] - 12s 13ms/sample - loss: 0.2301 - accuracy: 0.9228 - val_loss: 0.3801 - val_accuracy: 0.8889\n",
      "Epoch 13/50\n",
      "868/868 [==============================] - 12s 14ms/sample - loss: 0.2669 - accuracy: 0.9067 - val_loss: 0.3974 - val_accuracy: 0.8889\n",
      "Epoch 14/50\n",
      "868/868 [==============================] - 12s 13ms/sample - loss: 0.2688 - accuracy: 0.9090 - val_loss: 0.4387 - val_accuracy: 0.8562\n",
      "Epoch 15/50\n",
      "868/868 [==============================] - 12s 14ms/sample - loss: 0.2210 - accuracy: 0.9205 - val_loss: 0.3425 - val_accuracy: 0.9150\n",
      "Epoch 16/50\n",
      "868/868 [==============================] - 12s 14ms/sample - loss: 0.1563 - accuracy: 0.9551 - val_loss: 0.3557 - val_accuracy: 0.9150\n",
      "Epoch 17/50\n",
      "868/868 [==============================] - 12s 14ms/sample - loss: 0.1890 - accuracy: 0.9343 - val_loss: 0.4745 - val_accuracy: 0.8627\n",
      "Epoch 18/50\n",
      "868/868 [==============================] - 12s 14ms/sample - loss: 0.1843 - accuracy: 0.9378 - val_loss: 0.4767 - val_accuracy: 0.8824\n",
      "Epoch 19/50\n",
      "868/868 [==============================] - 12s 14ms/sample - loss: 0.1657 - accuracy: 0.9412 - val_loss: 0.3529 - val_accuracy: 0.9150\n",
      "Epoch 20/50\n",
      "868/868 [==============================] - 12s 14ms/sample - loss: 0.1333 - accuracy: 0.9654 - val_loss: 0.4818 - val_accuracy: 0.8431\n",
      "Epoch 21/50\n",
      "868/868 [==============================] - 12s 14ms/sample - loss: 0.1544 - accuracy: 0.9562 - val_loss: 0.4854 - val_accuracy: 0.8627\n",
      "Epoch 22/50\n",
      "868/868 [==============================] - 12s 14ms/sample - loss: 0.1329 - accuracy: 0.9528 - val_loss: 0.5064 - val_accuracy: 0.8824\n",
      "Epoch 23/50\n",
      "868/868 [==============================] - 12s 14ms/sample - loss: 0.1691 - accuracy: 0.9470 - val_loss: 0.5543 - val_accuracy: 0.8235\n",
      "Epoch 24/50\n",
      "868/868 [==============================] - 12s 14ms/sample - loss: 0.1610 - accuracy: 0.9447 - val_loss: 0.3649 - val_accuracy: 0.8954\n",
      "Epoch 25/50\n",
      "868/868 [==============================] - 13s 15ms/sample - loss: 0.1162 - accuracy: 0.9643 - val_loss: 0.4262 - val_accuracy: 0.8889\n",
      "Epoch 26/50\n",
      "868/868 [==============================] - 15s 17ms/sample - loss: 0.1272 - accuracy: 0.9551 - val_loss: 0.4020 - val_accuracy: 0.8954\n",
      "Epoch 27/50\n",
      "868/868 [==============================] - 13s 15ms/sample - loss: 0.0983 - accuracy: 0.9608 - val_loss: 0.3933 - val_accuracy: 0.9281\n",
      "Epoch 28/50\n",
      "868/868 [==============================] - 12s 14ms/sample - loss: 0.0768 - accuracy: 0.9724 - val_loss: 0.3917 - val_accuracy: 0.9281\n",
      "Epoch 29/50\n",
      "868/868 [==============================] - 13s 15ms/sample - loss: 0.0738 - accuracy: 0.9747 - val_loss: 0.4019 - val_accuracy: 0.9085\n",
      "Epoch 30/50\n",
      "868/868 [==============================] - 11s 13ms/sample - loss: 0.0591 - accuracy: 0.9850 - val_loss: 0.4011 - val_accuracy: 0.9085\n",
      "Epoch 31/50\n",
      "868/868 [==============================] - 10s 12ms/sample - loss: 0.0510 - accuracy: 0.9816 - val_loss: 0.4622 - val_accuracy: 0.9085\n",
      "Epoch 32/50\n",
      "868/868 [==============================] - 10s 12ms/sample - loss: 0.0381 - accuracy: 0.9896 - val_loss: 0.4463 - val_accuracy: 0.9150\n",
      "Epoch 33/50\n",
      "868/868 [==============================] - 10s 12ms/sample - loss: 0.0414 - accuracy: 0.9896 - val_loss: 0.5224 - val_accuracy: 0.8824\n",
      "Epoch 34/50\n",
      "868/868 [==============================] - 10s 12ms/sample - loss: 0.0476 - accuracy: 0.9850 - val_loss: 0.4708 - val_accuracy: 0.8954\n",
      "Epoch 35/50\n",
      "868/868 [==============================] - 13s 14ms/sample - loss: 0.0666 - accuracy: 0.9758 - val_loss: 0.4494 - val_accuracy: 0.8954\n",
      "Epoch 36/50\n",
      "868/868 [==============================] - 12s 14ms/sample - loss: 0.1571 - accuracy: 0.9424 - val_loss: 0.6647 - val_accuracy: 0.8431\n",
      "Epoch 37/50\n",
      "868/868 [==============================] - 12s 14ms/sample - loss: 0.1373 - accuracy: 0.9482 - val_loss: 0.8763 - val_accuracy: 0.7908\n",
      "Epoch 38/50\n",
      "868/868 [==============================] - 11s 12ms/sample - loss: 0.1263 - accuracy: 0.9585 - val_loss: 0.5234 - val_accuracy: 0.8889\n",
      "Epoch 39/50\n",
      "868/868 [==============================] - 13s 15ms/sample - loss: 0.1094 - accuracy: 0.9666 - val_loss: 0.4721 - val_accuracy: 0.9020\n",
      "Epoch 40/50\n",
      "868/868 [==============================] - 11s 12ms/sample - loss: 0.0715 - accuracy: 0.9793 - val_loss: 0.4906 - val_accuracy: 0.9150\n",
      "Epoch 41/50\n",
      "868/868 [==============================] - 13s 15ms/sample - loss: 0.0439 - accuracy: 0.9873 - val_loss: 0.6222 - val_accuracy: 0.9020\n",
      "Epoch 42/50\n",
      "868/868 [==============================] - 13s 15ms/sample - loss: 0.0614 - accuracy: 0.9758 - val_loss: 0.5382 - val_accuracy: 0.8497\n",
      "Epoch 43/50\n",
      "868/868 [==============================] - 13s 15ms/sample - loss: 0.0461 - accuracy: 0.9862 - val_loss: 0.5762 - val_accuracy: 0.8824\n",
      "Epoch 44/50\n",
      "868/868 [==============================] - 12s 13ms/sample - loss: 0.0334 - accuracy: 0.9896 - val_loss: 0.5118 - val_accuracy: 0.8954\n",
      "Epoch 45/50\n",
      "868/868 [==============================] - 16s 18ms/sample - loss: 0.0416 - accuracy: 0.9862 - val_loss: 0.4955 - val_accuracy: 0.9020\n",
      "Epoch 46/50\n",
      "868/868 [==============================] - 13s 15ms/sample - loss: 0.0273 - accuracy: 0.9908 - val_loss: 0.5046 - val_accuracy: 0.9085\n",
      "Epoch 47/50\n",
      "868/868 [==============================] - 12s 14ms/sample - loss: 0.0279 - accuracy: 0.9919 - val_loss: 0.4753 - val_accuracy: 0.8954\n",
      "Epoch 48/50\n",
      "868/868 [==============================] - 13s 15ms/sample - loss: 0.0186 - accuracy: 0.9942 - val_loss: 0.4942 - val_accuracy: 0.9020\n",
      "Epoch 49/50\n",
      "868/868 [==============================] - 12s 14ms/sample - loss: 0.0380 - accuracy: 0.9850 - val_loss: 0.4802 - val_accuracy: 0.8954\n",
      "Epoch 50/50\n",
      "868/868 [==============================] - 13s 14ms/sample - loss: 0.0248 - accuracy: 0.9942 - val_loss: 0.5337 - val_accuracy: 0.9020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1340f73d0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 50\n",
    "batch_size = 128\n",
    "\n",
    "# Fit the model weights.\n",
    "model2.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1, validation_data=(x_test, y_test)\n",
    ")\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            multiple                  896       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            multiple                  18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            multiple                  18464     \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            multiple                  18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             multiple                  43268     \n",
      "=================================================================\n",
      "Total params: 99,620\n",
      "Trainable params: 99,620\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153/1 - 0s - loss: 0.3302 - accuracy: 0.9020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5337015073868184, 0.9019608]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
